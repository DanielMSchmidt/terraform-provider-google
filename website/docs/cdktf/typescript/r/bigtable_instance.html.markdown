---
subcategory: "Cloud Bigtable"
description: |-
  Creates a Google Bigtable instance.
---


<!-- Please do not edit this file, it is generated. -->
# google_bigtable_instance

Creates a Google Bigtable instance. For more information see:

* [API documentation](https://cloud.google.com/bigtable/docs/reference/admin/rest/v2/projects.instances.clusters)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/bigtable/docs)


-> **Note**: It is strongly recommended to set `lifecycle { prevent_destroy = true }`
on instances in order to prevent accidental data loss. See
[Terraform docs](https://www.terraform.io/docs/configuration/resources.html#prevent_destroy)
for more information on lifecycle parameters.

-> **Note**: On newer versions of the provider, you must explicitly set `deletionProtection=false`
(and run `terraform apply` to write the field to state) in order to destroy an instance.
It is recommended to not set this field (or set it to true) until you're ready to destroy.


## Example Usage - Simple Instance

```typescript
import * as constructs from "constructs";
import * as cdktf from "cdktf";
/*Provider bindings are generated by running cdktf get.
See https://cdk.tf/provider-generation for more details.*/
import * as google from "./.gen/providers/google";
class MyConvertedCode extends cdktf.TerraformStack {
  constructor(scope: constructs.Construct, name: string) {
    super(scope, name);
    new google.bigtableInstance.BigtableInstance(this, "production-instance", {
      cluster: [
        {
          clusterId: "tf-instance-cluster",
          numNodes: 1,
          storageType: "HDD",
        },
      ],
      labels: {
        "my-label": "prod-label",
      },
      name: "tf-instance",
    });
  }
}

```

## Example Usage - Replicated Instance

```hcl
resource "google_bigtable_instance" "production-instance" {
  name = "tf-instance"

  # A cluster with fixed number of nodes.
  cluster {
    cluster_id   = "tf-instance-cluster1"
    num_nodes    = 1
    storage_type = "HDD"
    zone    = "us-central1-c"
  }

  # a cluster with auto scaling.
  cluster {
    cluster_id   = "tf-instance-cluster2"
    storage_type = "HDD"
    zone    = "us-central1-b"
    autoscaling_config {
      min_nodes = 1
      max_nodes = 3
      cpu_target = 50
    }
  }

  labels = {
    my-label = "prod-label"
  }
}
```


## Argument Reference

The following arguments are supported:

* `name` - (Required) The name (also called Instance Id in the Cloud Console) of the Cloud Bigtable instance. Must be 6-33 characters and must only contain hyphens, lowercase letters and numbers.

* `cluster` - (Required) A block of cluster configuration options. This can be specified at least once, and up 
to as many as possible within 8 cloud regions. Removing the field entirely from the config will cause the provider
to default to the backend value. See [structure below](#nested_cluster).

-----

* `project` - (Optional) The ID of the project in which the resource belongs. If it
    is not provided, the provider project is used.

* `instanceType` - (Optional, Deprecated) The instance type to create. One of `"development"` or `"production"`. Defaults to `"production"`.
    It is recommended to leave this field unspecified since the distinction between `"development"` and `"production"` instances is going away,
    and all instances will become `"production"` instances. This means that new and existing `"development"` instances will be converted to
    `"production"` instances. It is recommended for users to use `"production"` instances in any case, since a 1-node `"production"` instance
    is functionally identical to a `"development"` instance, but without the accompanying restrictions.

* `displayName` - (Optional) The human-readable display name of the Bigtable instance. Defaults to the instance `name`.

* `deletionProtection` - (Optional) Whether or not to allow Terraform to destroy the instance. Unless this field is set to false
in Terraform state, a `terraform destroy` or `terraform apply` that would delete the instance will fail.

* `labels` - (Optional) A set of key/value label pairs to assign to the resource. Label keys must follow the requirements at https://cloud.google.com/resource-manager/docs/creating-managing-labels#requirements.


-----

<a name="nested_cluster"></a>The `cluster` block supports the following arguments:

* `clusterId` - (Required) The ID of the Cloud Bigtable cluster. Must be 6-30 characters and must only contain hyphens, lowercase letters and numbers.

* `zone` - (Optional) The zone to create the Cloud Bigtable cluster in. If it not
specified, the provider zone is used. Each cluster must have a different zone in the same region. Zones that support
Bigtable instances are noted on the [Cloud Bigtable locations page](https://cloud.google.com/bigtable/docs/locations).

* `numNodes` - (Optional) The number of nodes in your Cloud Bigtable cluster.
Required, with a minimum of `1` for each cluster in an instance.

* `autoscalingConfig` - (Optional) [Autoscaling](https://cloud.google.com/bigtable/docs/autoscaling#parameters) config for the cluster, contains the following arguments:

  * `minNodes` - (Required) The minimum number of nodes for autoscaling.
  * `maxNodes` - (Required) The maximum number of nodes for autoscaling.
  * `cpuTarget` - (Required) The target CPU utilization for autoscaling, in percentage. Must be between 10 and 80.
  * `storageTarget` - The target storage utilization for autoscaling, in GB, for each node in a cluster. This number is limited between 2560 (2.5TiB) and 5120 (5TiB) for a SSD cluster and between 8192 (8TiB) and 16384 (16 TiB) for an HDD cluster. If not set, whatever is already set for the cluster will not change, or if the cluster is just being created, it will use the default value of 2560 for SSD clusters and 8192 for HDD clusters.

!> **Warning**: Only one of `autoscalingConfig` or `numNodes` should be set for a cluster. If both are set, `numNodes` is ignored. If none is set, autoscaling will be disabled and sized to the current node count.

* `storageType` - (Optional) The storage type to use. One of `"ssd"` or
`"hdd"`. Defaults to `"ssd"`.

* `kmsKeyName` - (Optional) Describes the Cloud KMS encryption key that will be used to protect the destination Bigtable cluster. The requirements for this key are: 1) The Cloud Bigtable service account associated with the project that contains this cluster must be granted the `cloudkmsCryptoKeyEncrypterDecrypter` role on the CMEK key. 2) Only regional keys can be used and the region of the CMEK key must match the region of the cluster.

-> **Note**: Removing the field entirely from the config will cause the provider to default to the backend value.

!> **Warning:** Modifying the `storageType`, `zone` or `kmsKeyName` of an existing cluster (by
`clusterId`) will cause Terraform to delete/recreate the entire
`googleBigtableInstance` resource. If these values are changing, use a new
`clusterId`.

## Attributes Reference

In addition to the arguments listed above, the following computed attributes are exported:

* `id` - an identifier for the resource with format `projects/{{project}}/instances/{{name}}`

## Import

Bigtable Instances can be imported using any of these accepted formats:

```
$ terraform import google_bigtable_instance.default projects/{{project}}/instances/{{name}}
$ terraform import google_bigtable_instance.default {{project}}/{{name}}
$ terraform import google_bigtable_instance.default {{name}}
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-b2e90ac2dd3056980c2a89de3c8968626238392a2cebc4043f5090e8ae930881 -->